#!/usr/bin/env python3
"""
æµ‹è¯•æ•°æ®åŠ è½½å™¨ä¿®å¤
"""

import torch
from torch.utils.data import DataLoader
from data_loaders.humanml.data.dataset_abs import HumanML3D

def test_dataloader():
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½å™¨ä¿®å¤")
    print("=" * 50)
    
    try:
        # åˆ›å»ºæ•°æ®é›†
        print("ğŸ“ åˆ›å»ºæ•°æ®é›†...")
        dataset = HumanML3D(
            mode='train',
            datapath='./dataset/humanml_opt.txt',
            split="train",
            use_multiprocessing=True,
            num_workers=64
        )
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        # æµ‹è¯•å•ä¸ªæ ·æœ¬è·å–
        print("\nğŸ” æµ‹è¯•å•ä¸ªæ ·æœ¬è·å–...")
        if len(dataset) > 0:
            sample = dataset[0]
            print(f"âœ… æ ·æœ¬è·å–æˆåŠŸ")
            print(f"ğŸ“Š æ ·æœ¬ç±»å‹: {type(sample)}")
            print(f"ğŸ“Š æ ·æœ¬é•¿åº¦: {len(sample)}")
        else:
            print("âš ï¸  æ•°æ®é›†ä¸ºç©º")
            return
        
        # æµ‹è¯•DataLoader
        print("\nğŸ”„ æµ‹è¯•DataLoader...")
        dataloader = DataLoader(
            dataset,
            batch_size=4,
            shuffle=True,
            num_workers=2,  # ä½¿ç”¨è¾ƒå°‘çš„workerè¿›è¡Œæµ‹è¯•
            drop_last=True
        )
        
        print(f"âœ… DataLoaderåˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“Š DataLoaderé•¿åº¦: {len(dataloader)}")
        
        # æµ‹è¯•è·å–ä¸€ä¸ªbatch
        print("\nğŸ“¦ æµ‹è¯•è·å–batch...")
        for i, batch in enumerate(dataloader):
            print(f"âœ… æˆåŠŸè·å–ç¬¬ {i+1} ä¸ªbatch")
            print(f"ğŸ“Š Batchç±»å‹: {type(batch)}")
            print(f"ğŸ“Š Batché•¿åº¦: {len(batch)}")
            
            # åªæµ‹è¯•ç¬¬ä¸€ä¸ªbatch
            if i == 0:
                for j, item in enumerate(batch):
                    if isinstance(item, torch.Tensor):
                        print(f"  {j}: Tensor shape {item.shape}")
                    elif isinstance(item, str):
                        print(f"  {j}: String length {len(item)}")
                    else:
                        print(f"  {j}: {type(item).__name__}")
            break
            
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_index_validation():
    """æµ‹è¯•ç´¢å¼•éªŒè¯"""
    print("\nğŸ” æµ‹è¯•ç´¢å¼•éªŒè¯")
    print("=" * 30)
    
    try:
        dataset = HumanML3D(
            mode='train',
            datapath='./dataset/humanml_opt.txt',
            split="train",
            use_multiprocessing=False,  # ä½¿ç”¨å•è¿›ç¨‹é¿å…å¤æ‚æ€§
            num_workers=1
        )
        
        print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        # æµ‹è¯•æ­£å¸¸ç´¢å¼•
        if len(dataset) > 0:
            print("âœ… æ­£å¸¸ç´¢å¼•æµ‹è¯•é€šè¿‡")
            dataset[0]
        
        # æµ‹è¯•è´Ÿç´¢å¼•
        try:
            dataset[-1]
            print("âŒ è´Ÿç´¢å¼•åº”è¯¥å¤±è´¥ä½†æ²¡æœ‰å¤±è´¥")
        except ValueError as e:
            print(f"âœ… è´Ÿç´¢å¼•æ­£ç¡®è¢«æ‹’ç»: {e}")
        
        # æµ‹è¯•è¶…å‡ºèŒƒå›´çš„ç´¢å¼•
        try:
            dataset[len(dataset) + 1]
            print("âŒ è¶…å‡ºèŒƒå›´ç´¢å¼•åº”è¯¥å¤±è´¥ä½†æ²¡æœ‰å¤±è´¥")
        except IndexError as e:
            print(f"âœ… è¶…å‡ºèŒƒå›´ç´¢å¼•æ­£ç¡®è¢«æ‹’ç»: {e}")
            
    except Exception as e:
        print(f"âŒ ç´¢å¼•éªŒè¯æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    test_dataloader()
    test_index_validation()
    print("\nğŸ æµ‹è¯•å®Œæˆï¼") 